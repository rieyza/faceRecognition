{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"DATASET/\"\n",
    "train = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  path,\n",
    "  labels = \"inferred\",\n",
    "  label_mode = \"categorical\",\n",
    "  color_mode = \"rgb\",\n",
    "  batch_size = 32,\n",
    "  image_size = (160,160),\n",
    "  seed = 32,\n",
    "  subset = \"training\",\n",
    "  validation_split = 0.2  \n",
    ")\n",
    "valid = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  path,\n",
    "  labels = \"inferred\",\n",
    "  label_mode = \"categorical\",\n",
    "  color_mode = \"rgb\",\n",
    "  batch_size = 32,\n",
    "  image_size = (160,160),\n",
    "  seed = 1234,\n",
    "  subset = \"validation\",\n",
    "  validation_split = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train\n",
    "\n",
    "classnames = train.class_names\n",
    "classes = len(classnames)\n",
    "classnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "tf.keras.layers.Rescaling(1./255, input_shape=(160,160, 3)),\n",
    "tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "tf.keras.layers.MaxPooling2D(),\n",
    "tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "tf.keras.layers.MaxPooling2D(),\n",
    "tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "tf.keras.layers.MaxPooling2D(),\n",
    "tf.keras.layers.Flatten(),\n",
    "tf.keras.layers.Dense(128, activation='relu'),\n",
    "tf.keras.layers.Dense(classes, activation='softmax') \n",
    "])\n",
    "model.compile(loss = tf.keras.losses.CategoricalCrossentropy(),optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train, validation_data = valid, epochs = 5, batch_size = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    _, img = cap.read()\n",
    "    #img = cv2.rotate(img, cv2.ROTATE_180)\n",
    "    if _:\n",
    "        rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        faces = faceCascade.detectMultiScale(rgb, 1.9, 5)\n",
    "        \n",
    "        for (x,y,w,h) in faces:\n",
    "            imgROI = rgb[y:y+h, x:x+w]\n",
    "            imgResize = cv2.resize(imgROI, (160,160))\n",
    "\n",
    "            img_array = tf.keras.utils.img_to_array(imgResize)\n",
    "            img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "            predictions = model.predict(img_array)\n",
    "            score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "            text = \"ID: {}, {:.2f}%.\".format(classnames[np.argmax(score)], 100 * np.max(score))\n",
    "\n",
    "            image = cv2.rectangle(img, (x,y), (x+w, y+h), (0,255,255), 1)\n",
    "            cv2.putText(image, text, (x, y-10), cv2.FONT_HERSHEY_COMPLEX_SMALL, 0.9, (0,255,255), 1)\n",
    "            cv2.imshow(\"Camera\", img)\n",
    "    else:\n",
    "       print('No Camera')\n",
    "       cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = input(\"ID\")\n",
    "ids = str(id)\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "for image in glob(\"IMAGES/\" + ids + \"/*.jpg\"):\n",
    "    img = cv2.imread(image)\n",
    "    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    faces = faceCascade.detectMultiScale(rgb, 1.9, 5)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        imgROI = rgb[y:y+h, x:x+w]\n",
    "        imgResize = cv2.resize(imgROI, (160,160))\n",
    "        img_array = tf.keras.utils.img_to_array(imgResize)\n",
    "        img_array = tf.expand_dims(img_array, 0)\n",
    "        predictions = model.predict(img_array)\n",
    "        score = tf.nn.softmax(predictions[0])\n",
    "        text = \"ID: {}, {:.2f}%.\".format(classnames[np.argmax(score)], 100 * np.max(score))\n",
    "        print (text)\n",
    "\n",
    "        cv2.imwrite(\"file.jpg\", imgResize)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('face-recognition')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf35c52f22082765708e3a9c257de4117348c619044f92dbdf7d609e6f9399a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
